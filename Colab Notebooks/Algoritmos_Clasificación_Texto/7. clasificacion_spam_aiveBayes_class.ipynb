{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"7. clasificacion_spam_aiveBayes_class.ipynb","provenance":[{"file_id":"1PqnvqGWqb7wO74bDt8LcjILF6N1pbeMe","timestamp":1639178692323}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"iyAhmlbo24VQ"},"source":["import math\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H7BKMjaR28jW"},"source":["os.listdir('corpus1/spam')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fSHovwBR1ZfA"},"source":["## Preparación del corpus de emails"]},{"cell_type":"code","metadata":{"id":"w8P_ve0L0Gyu","colab":{"base_uri":"https://localhost:8080/","height":82},"executionInfo":{"status":"ok","timestamp":1594956494407,"user_tz":300,"elapsed":7164,"user":{"displayName":"Francisco Camacho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9-RzPl8GwmwlgVzviB9WCCmO7S-tSRs4UBCgR=s64","userId":"03320326049189164988"}},"outputId":"94795fbe-f893-40b9-90d2-746ce90be8d6"},"source":["!git clone https://github.com/pachocamacho1990/datasets"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'datasets'...\n","remote: Enumerating objects: 39, done.\u001b[K\n","remote: Total 39 (delta 0), reused 0 (delta 0), pack-reused 39\u001b[K\n","Unpacking objects: 100% (39/39), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MFrqDzfu04pJ"},"source":["! unzip datasets/email/plaintext/corpus1.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJTtSZto1jC1","colab":{"base_uri":"https://localhost:8080/","height":32},"executionInfo":{"status":"ok","timestamp":1594962582237,"user_tz":300,"elapsed":360,"user":{"displayName":"Francisco Camacho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9-RzPl8GwmwlgVzviB9WCCmO7S-tSRs4UBCgR=s64","userId":"03320326049189164988"}},"outputId":"725116b6-35ad-4a1c-ecf4-f5f073c5e456"},"source":["data = []\n","clases = []\n","#lectura de spam data\n","for file in os.listdir('corpus1/spam'):\n","  with open('corpus1/spam/'+file, encoding='latin-1') as f:\n","    data.append(f.read())\n","    clases.append('spam')\n","#lectura de ham data\n","for file in os.listdir('corpus1/ham'):\n","  with open('corpus1/ham/'+file, encoding='latin-1') as f:\n","    data.append(f.read())\n","    clases.append('ham')\n","len(data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5172"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"0NOb61Ik7MI-"},"source":["## Construcción de modelo Naive Bayes"]},{"cell_type":"markdown","metadata":{"id":"IXXlUjrJ7DjR"},"source":["### Tokenizador de Spacy\n","\n","* Documentación: https://spacy.io/api/tokenizer\n","* ¿Cómo funciona el tokenizador? https://spacy.io/usage/linguistic-features#how-tokenizer-works"]},{"cell_type":"code","metadata":{"id":"ePmKCQpw4cqK"},"source":["from spacy.tokenizer import Tokenizer\n","from spacy.lang.en import English\n","\n","nlp = English()\n","tokenizer = Tokenizer(nlp.vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oF1cGmZ293OA","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1594962545451,"user_tz":300,"elapsed":455,"user":{"displayName":"Francisco Camacho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9-RzPl8GwmwlgVzviB9WCCmO7S-tSRs4UBCgR=s64","userId":"03320326049189164988"}},"outputId":"17490c87-9c24-420f-e251-5324b2357bd9"},"source":["print([t.text for t in tokenizer(data[0])])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Subject:', 'brand', 'new', 'teenager', 'peeing', '\\n', 'you', 'don', \"'\", 't', 'know', 'me', 'from', 'adam', '.', ':', ')', 'iyakubonana', '\\n', 'nothing', 'that', 'you', 'have', 'not', 'given', 'away', 'will', 'ever', 'be', 'really', 'yours', '.', '\\n', 'i', 'don', \"'\", 't', 'deserve', 'this', 'award', ',', 'but', 'i', 'have', 'arthritis', ',', 'and', 'i', 'don', \"'\", 't', 'deserve', 'that', ',', 'either', '.', 'the', 'most', 'important', 'thing', 'a', 'father', 'can', 'do', 'for', 'his', 'children', 'is', 'to', 'love', 'their', 'mother', '.', '\\n', 'tricks', 'and', 'treachery', 'are', 'the', 'practice', 'of', 'fools', ',', 'that', 'don', \"'\", 't', 'have', 'brains', 'enough', 'to', 'be', 'honest', '.', '\\n', 'a', 'heart', 'that', 'loves', 'is', 'always', 'young', '.', '\\n', 'if', 'you', 'drink', ',', 'don', \"'\", 't', 'drive', '.', 'don', \"'\", 't', 'even', 'putt', '.', '\\n', 'husbands', 'never', 'become', 'good', 'they', 'merely', 'become', 'proficient', '.', '\\n', 'only', 'from', 'the', 'heart', 'can', 'you', 'touch', 'the', 'sky', '.', '\\n', 'even', 'if', 'it', 'is', 'to', 'be', ',', 'what', 'end', 'do', 'you', 'serve', 'by', 'running', 'to', 'distress', '?', 'it', 'is', 'a', 'terrible', 'thing', 'to', 'look', 'over', 'your', 'shoulder', 'when', 'you', 'are', 'trying', 'to', 'lead', '-', '-', 'and', 'find', 'no', 'one', 'there', '.', '\\n', 'i', 'hated', 'her', 'now', 'with', 'a', 'hatred', 'more', 'fatal', 'than', 'indifference', 'because', 'it', 'was', 'the', 'other', 'side', 'of', 'love', '.', '\\n', 'reading', 'makes', 'a', 'full', 'man', ',', 'meditation', 'a', 'profound', 'man', ',', 'discourse', 'a', 'clear', 'man', '.', '\\n', 'a', 'few', 'strong', 'instincts', 'and', 'a', 'few', 'plain', 'rules', 'suffice', 'us', '.', '\\n', 'we', 'are', 'all', 'sentenced', 'to', 'solitary', 'confinement', 'inside', 'our', 'own', 'skins', ',', 'for', 'life', '.', '\\n', 'eroticism', 'is', 'assenting', 'to', 'life', 'even', 'in', 'death', '.', '\\n', 'truly', 'great', 'friends', 'are', 'hard', 'to', 'find', ',', 'difficult', 'to', 'leave', ',', 'and', 'impossible', 'to', 'forget', '.', '\\n', 'the', 'weeping', 'of', 'an', 'heir', 'is', 'laughter', 'in', 'disguise', '.', 'the', 'harder', 'i', 'work', 'the', 'luckier', 'i', 'get', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m4i6IQGx7Tul"},"source":["### Clase principal para el algoritmo\n","\n","Recuerda que la clase más probable viene dada por (en espacio de cómputo logarítmico): \n","\n","\n","$$\\hat{c} = {\\arg \\max}_{(c)}\\log{P(c)}\n"," +\\sum_{i=1}^n\n","\\log{ P(f_i \\vert c)}\n","$$\n","\n","Donde, para evitar casos atípicos, usaremos el suavizado de Laplace así:\n","\n","$$\n","P(f_i \\vert c) = \\frac{C(f_i, c)+1}{C(c) + \\vert V \\vert}\n","$$\n","\n","siendo $\\vert V \\vert$ la longitud del vocabulario de nuestro conjunto de entrenamiento. "]},{"cell_type":"code","metadata":{"id":"nTgbTusfyPHW"},"source":["import numpy as np\n","\n","class NaiveBayesClassifier():\n","  nlp = English()\n","  tokenizer = Tokenizer(nlp.vocab)\n","  \n","  def tokenize(self, doc):\n","    return  [t.text.lower() for t in tokenizer(doc)]\n","\n","  def word_counts(self, words):\n","    wordCount = {}\n","    for w in words: \n","      if w in wordCount.keys():\n","        wordCount[w] += 1\n","      else:\n","        wordCount[w] = 1\n","    return wordCount\n","\n","  def fit(self, data, clases):\n","    n = len(data)\n","    self.unique_clases = set(clases)\n","    self.vocab = set()\n","    self.classCount = {} #C(c)\n","    self.log_classPriorProb = {} #P(c)\n","    self.wordConditionalCounts = {} #C(w|c)\n","    #conteos de clases\n","    for c in clases:\n","      if c in self.classCount.keys():\n","        self.classCount[c] += 1\n","      else:\n","        self.classCount[c] = 1\n","    # calculo de P(c)\n","    for c in self.classCount.keys():\n","      self.log_classPriorProb[c] = math.log(self.classCount[c]/n)\n","      self.wordConditionalCounts[c] = {}\n","    # calculo de C(w|c)\n","    for text, c in zip(data, clases):\n","      counts = self.word_counts(self.tokenize(text))\n","      for word, count in counts.items():\n","        if word not in self.vocab:\n","          self.vocab.add(word)\n","        if word not in self.wordConditionalCounts[c]:\n","          self.wordConditionalCounts[c][word] = 0.0\n","        self.wordConditionalCounts[c][word] += count\n","\n","  def predict(self, data):\n","    results = []\n","    for text in data:\n","      words = set(self.tokenize(text))\n","      scoreProb = {}\n","      for word in words: \n","        if word not in self.vocab: continue #ignoramos palabras nuevas\n","        #suavizado Laplaciano para P(w|c)\n","        for c in self.unique_clases:\n","          log_wordClassProb = math.log(\n","              (self.wordConditionalCounts[c].get(word, 0.0)+1)/(self.classCount[c]+len(self.vocab)))\n","          scoreProb[c] = scoreProb.get(c, self.log_classPriorProb[c]) + log_wordClassProb\n","      arg_maxprob = np.argmax(np.array(list(scoreProb.values())))\n","      results.append(list(scoreProb.keys())[arg_maxprob])\n","    return results\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EE9Aus71bdUx"},"source":["### Utilidades de Scikit Learn\n","* `train_test_split`: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n","\n","* `accuracy_score`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n","\n","* `precision_score`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n","\n","* `recall_score`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html"]},{"cell_type":"code","metadata":{"id":"m95539uQZaDZ"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","data_train, data_test, clases_train, clases_test = train_test_split(data, clases, test_size=0.10, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Qrb-42APpHM"},"source":["classifier = NaiveBayesClassifier()\n","classifier.fit(data_train, clases_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdzx7-5xXJfD"},"source":["clases_predict = classifier.predict(data_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0whDaiFwayf5","colab":{"base_uri":"https://localhost:8080/","height":32},"executionInfo":{"status":"ok","timestamp":1594967409845,"user_tz":300,"elapsed":454,"user":{"displayName":"Francisco Camacho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9-RzPl8GwmwlgVzviB9WCCmO7S-tSRs4UBCgR=s64","userId":"03320326049189164988"}},"outputId":"54ffe0bc-51ce-4f8b-b1eb-3145ad48ed46"},"source":["accuracy_score(clases_test, clases_predict)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8552123552123552"]},"metadata":{"tags":[]},"execution_count":130}]},{"cell_type":"code","metadata":{"id":"FQM3QjN1dlIu","colab":{"base_uri":"https://localhost:8080/","height":32},"executionInfo":{"status":"ok","timestamp":1594967421416,"user_tz":300,"elapsed":478,"user":{"displayName":"Francisco Camacho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9-RzPl8GwmwlgVzviB9WCCmO7S-tSRs4UBCgR=s64","userId":"03320326049189164988"}},"outputId":"ade43f9a-8251-4686-db3a-da620d4d304e"},"source":["precision_score(clases_test, clases_predict, average=None, zero_division=1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.82876712, 1.        ])"]},"metadata":{"tags":[]},"execution_count":131}]},{"cell_type":"code","metadata":{"id":"KiWQMX0Jdmnt","colab":{"base_uri":"https://localhost:8080/","height":32},"executionInfo":{"status":"ok","timestamp":1594967492971,"user_tz":300,"elapsed":366,"user":{"displayName":"Francisco Camacho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9-RzPl8GwmwlgVzviB9WCCmO7S-tSRs4UBCgR=s64","userId":"03320326049189164988"}},"outputId":"202c982f-3abe-4b5c-f5e7-46e2bc624a22"},"source":["recall_score(clases_test, clases_predict, average=None, zero_division=1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.        , 0.51612903])"]},"metadata":{"tags":[]},"execution_count":132}]}]}